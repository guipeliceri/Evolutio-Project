{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guipeliceri/Evolutio-Project/blob/main/01-Cancer_Diagnosis/Cancer_Diagnosis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**01 - Cancer Diagnosis**\n",
        "\n",
        "Bem vindos a nossa primeira atividade do projeto!\n",
        "A tarefa √© auxiliar na detec√ß√£o de c√¢nceres de mama.\n",
        "\n",
        "Nosso objetivo √© construir e treinar um \"c√©rebro\" artificial (uma rede neural) que aprender√° a partir de dados de exames reais. Ao final, este c√©rebro ser√° capaz de analisar as caracter√≠sticas de um tumor e prever se ele √© maligno (cancer√≠geno) ou benigno (n√£o cancer√≠geno).\n",
        "\n",
        "Vamos come√ßar!\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**CR√âDITOS**: O c√≥digo utilizado vem do usu√°rio\n",
        "GitHub: https://github.com/KhanradCoder\n",
        "\n",
        "E seu v√≠deo explicativo: https://www.youtube.com/watch?v=z1PGJ9quPV8\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Passo 1: Carregando Nossos Dados** üìÇ\n",
        "- Na pasta dessa primeira atividade h√° o arquivo cancer.csv, abra-o e clique em \"Download Raw File\" na parte superior\n",
        "- Aqui dentro da p√°gina do Colab, clique no √≠cone de pasta \"File\" e clique no bot√£o \"Upload to session storage\"\n",
        "\n",
        "Com os dados inseridos, agora podemos manipul√°-los! Tudo come√ßa com os dados. Nesses dados, cada linha representa um tumor e cada coluna uma caracter√≠stica medida (raio, textura, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "**Passo 2: Criando o Dataset**\n"
      ],
      "metadata": {
        "id": "hKT8lOWwvnUw"
      },
      "id": "hKT8lOWwvnUw"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('cancer.csv')"
      ],
      "metadata": {
        "id": "7hNier8H59Dr"
      },
      "id": "7hNier8H59Dr",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*import pandas as pd*\n",
        "\n",
        "- O que ela faz? Ela importa uma \"biblioteca\" (uma caixa de ferramentas de c√≥digo) chamada *pandas* para o nosso ambiente de trabalho.\n",
        "\n",
        "- A biblioteca *pandas* √© a ferramenta mais famosa e poderosa do Python para manipula√ß√£o e an√°lise de dados. Ela nos permite ler, limpar, transformar e entender dados de forma eficiente, especialmente dados em formato de tabela, como os de uma planilha do Excel.\n",
        "- *as pd* √© um apelido (em ingl√™s, alias). Programadores gostam de ser eficientes. Em vez de escrever *pandas* toda vez que precisarmos usar uma de suas ferramentas, a comunidade global de Python concordou em usar o apelido *pd*\n",
        "\n",
        "Analogia: a biblioteca *pandas* √© uma caixa de ferramentas e *pd* √© um apelido para da caixa de ferramentas, para acharmos as ferramentas mais facilmente\n",
        "\n",
        "---\n",
        "\n",
        "*dataset = pd.read_csv('cancer.csv')*\n",
        "- O que ela faz? Esta linha l√™ o arquivo cancer.csv e carrega todo o seu conte√∫do para dentro de uma vari√°vel chamada dataset.\n",
        "- pd.read_csv(...): Aqui estamos usando a ferramenta *read_csv* da nossa caixa pd. O nome √© autoexplicativo: ela √© especializada em ler arquivos CSV (Comma-Separated Values), que √© o formato de planilha mais comum do mundo, onde os valores s√£o separados por v√≠rgulas. No caso, ele est√° lendo *cancer.csv*\n",
        "- dataset =: O resultado da leitura n√£o pode ficar solto. N√≥s o \"guardamos\" ou \"atribu√≠mos\" a uma vari√°vel chamada dataset. Agora, a vari√°vel dataset cont√©m todos os dados do arquivo, organizados em uma estrutura de tabela super poderosa que o pandas chama de DataFrame.\n",
        "\n",
        "---\n",
        "\n",
        "**Passo 3: Separando X e Y**"
      ],
      "metadata": {
        "id": "w0BRu3GP6A4w"
      },
      "id": "w0BRu3GP6A4w"
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset.drop(columns=[\"diagnosis(1=m, 0=b)\"])\n",
        "\n",
        "y = dataset[\"diagnosis(1=m, 0=b)\"]"
      ],
      "metadata": {
        "id": "pGhmzLtT8sxj"
      },
      "id": "pGhmzLtT8sxj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*x = dataset.drop(columns=[\"diagnosis(1=m, 0=b)\"])*\n",
        "\n",
        "- O que ela faz: Ela cria uma nova tabela, chamada x, que √© uma c√≥pia de todo o dataset original, EXCETO pela coluna do diagn√≥stico.\n",
        "- Como ela faz isso: Usamos a fun√ß√£o *.drop()* do pandas, que serve para remover linhas ou colunas.\n",
        "- columns=[\"...\"]: Especificamos que queremos remover uma coluna (e n√£o uma linha) e passamos o nome exato da coluna a ser removida: \"diagnosis(1=m, 0=b)\".\n",
        "\n",
        "No jarg√£o de Machine Learning, x √© a nossa matriz de features (evid√™ncias)\n",
        "\n",
        "---\n",
        "\n",
        "*y = dataset[\"diagnosis(1=m, 0=b)\"]*\n",
        "Esta linha cria a nossa vari√°vel y.\n",
        "\n",
        "- O que ela faz: Ela cria uma nova vari√°vel, chamada y, que cont√©m APENAS a coluna do diagn√≥stico e mais nada.\n",
        "- Como ela faz isso: *dataset[\"...\"]:* Esta √© a sintaxe do pandas para selecionar uma ou mais colunas espec√≠ficas. Ao passar o nome da coluna \"diagnosis(1=m, 0=b)\", estamos dizendo: \"Do meu dataset inteiro, me d√™ apenas esta coluna.\"\n",
        "\n",
        "No jarg√£o de Machine Learning, y √© o nosso vetor alvo (resposta)\n",
        "\n",
        "---\n",
        "\n",
        " **Por que fazemos essa separa√ß√£o?**\n",
        "\n",
        " Este √© o conceito central do Aprendizado Supervisionado\n",
        "\n",
        "N√≥s queremos treinar nosso modelo de Intelig√™ncia Artificial para que ele aprenda a prever y (o diagn√≥stico) a partir de x (as evid√™ncias).\n",
        "\n",
        "Para fazer isso, n√≥s damos ao modelo as duas coisas durante o treinamento:\n",
        "\n",
        "As evid√™ncias (x)\n",
        "As respostas corretas para essas evid√™ncias (y)\n",
        "E dizemos ao modelo: \"Olhe para estas evid√™ncias e para estas respostas. Encontre os padr√µes. Aprenda a rela√ß√£o entre x e y para que, no futuro, quando eu te der um x novo que voc√™ nunca viu, voc√™ consiga me dizer qual √© o y correto.\"\n",
        "\n",
        "---\n",
        "\n",
        "**Passo 4: Dividir dados para o treinamento e o teste**"
      ],
      "metadata": {
        "id": "7OdNA5W-Aini"
      },
      "id": "7OdNA5W-Aini"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "a9D0hzMnEYMK"
      },
      "id": "a9D0hzMnEYMK",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*from sklearn.model_selection import train_test_split*\n",
        "\n",
        "- O que ela faz: Ela importa para o nosso c√≥digo a fun√ß√£o espec√≠fica train_test_split de dentro da gigantesca biblioteca scikit-learn.\n",
        "- O que √© a biblioteca scikit-learn: Se o pandas √© a nossa caixa de ferramentas para manipular dados, o scikit-learn (apelido sklearn) √© a nossa caixa de ferramentas para fazer Machine Learning. √â com essa biblioteca que os algoritmos de Aprendizado de M√°quina atuam no projeto, buscando padr√µes nos dados por exemplo\n",
        "\n",
        "---\n",
        "*x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)*\n",
        "\n",
        "\n",
        "\n",
        "**L√≥gica**\n",
        "\n",
        "Imagine que voc√™ vai dar uma prova para um aluno. Se voc√™ entregar as perguntas da prova para ele estudar, ele vai decorar as respostas e tirar 10. Mas ele realmente aprendeu a mat√©ria? N√£o. Ele apenas memorizou.\n",
        "\n",
        "Com a IA, √© a mesma coisa.\n",
        "\n",
        "Se treinarmos e testarmos nosso modelo com os mesmos dados, ele pode simplesmente \"decorar\" as respostas. Ele teria uma performance de 100%, mas seria in√∫til no mundo real com dados novos. Isso se chama **overfitting**.\n",
        "Ao usar o conjunto de treino (x_train, y_train), n√≥s deixamos nosso modelo estudar e aprender os padr√µes.\n",
        "Depois que ele est√° treinado, n√≥s o desafiamos com a prova final (x_test), dados que ele nunca viu antes.\n",
        "S√≥ ent√£o comparamos as previs√µes dele com o gabarito oficial (y_test) para ver se ele realmente aprendeu e generalizou o conhecimento, ou se apenas decorou.\n",
        "\n",
        "Assim:\n",
        "\n",
        "- train_test_split(...): Estamos chamando a fun√ß√£o que acabamos de importar.\n",
        "(x, y, ...): Os primeiros argumentos s√£o os dados que queremos dividir: nossa tabela de evid√™ncias x e nosso gabarito y.\n",
        "- test_size=0.2: Este √© o par√¢metro mais importante aqui. Estamos dizendo √† fun√ß√£o para reservar 20% (0.2) dos dados para o conjunto de teste. Consequentemente, os outros 80% ser√£o usados para o conjunto de treino. (Essa propor√ß√£o 80/20 √© um padr√£o muito comum).\n",
        "- x_train, x_test, y_train, y_test =: A fun√ß√£o train_test_split √© especial porque ela n√£o devolve apenas uma, mas quatro coisas, nesta ordem exata:\n",
        "-- x_train: Material de Estudo (Perguntas). Cont√©m 80% das evid√™ncias (x).\n",
        "-- x_test: Prova Final (Perguntas). Cont√©m os 20% restantes das evid√™ncias (x).\n",
        "-- y_train: Gabarito do Material de Estudo (Respostas). Cont√©m os diagn√≥sticos corretos para o x_train.\n",
        "-- y_test: Gabarito da Prova Final (Respostas). Cont√©m os diagn√≥sticos corretos para o x_test.\n",
        "<br>\n",
        "<br>\n",
        "A fun√ß√£o garante que a linha 10 de x_train corresponde √† linha 10 de y_train, e assim por diante.\n",
        "\n",
        "---\n",
        "\n",
        "**Passo 5: Vamos prweparar o treino da nossa IA!**"
      ],
      "metadata": {
        "id": "FFqUm1SAE-Sx"
      },
      "id": "FFqUm1SAE-Sx"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "PUjlWEkfJBVn"
      },
      "id": "PUjlWEkfJBVn",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "√ìtimo! Chegamos na parte da constru√ß√£o, o momento em que realmente come√ßamos a montar a nossa Intelig√™ncia Artificial\n",
        "\n",
        "*import tensorflow as tf*\n",
        "\n",
        "Esta linha √© sobre pegar a caixa de ferramentas mais poderosa da nossa oficina.\n",
        "\n",
        "- O que ela faz: Ela importa a biblioteca *TensorFlow* para o nosso projeto.\n",
        "- Por que TensorFlow: Se o *pandas* era a nossa caixa de ferramentas para arrumar os dados, e o *scikit-learn* para tarefas gerais de Machine Learning, o *TensorFlow* √© a nossa oficina de engenharia pesada, especializada em construir e treinar \"c√©rebros\" artificiais, as famosas Redes Neurais. √â uma das ferramentas mais utilizadas no mundo para Deep Learning, criada pelo Google.\n",
        "- Por que as *tf*: Bom, acho que voc√™ j√° deve saber, certo? Sim, √© apenas outro apelido dado para a biblioteca, assim como *pd* do *pandas*\n",
        "\n",
        "---\n",
        "\n",
        "*model = tf.keras.models.Sequential()*\n",
        "\n",
        "- O que ela faz: Esta linha cria o \"esqueleto\" ou a \"base\" do nosso modelo de rede neural.\n",
        "- Vamos quebrar em partes:\n",
        "-- tf.keras: Keras √© uma API do TensorFlow que funciona como uma interface de \"alto n√≠vel\". Em outras palavras, ele torna o processo de construir redes neurais muito mais f√°cil e intuitivo, como se fosse um conjunto de plantas e moldes pr√©-fabricados.\n",
        "-- .models.Sequential(): Estamos escolhendo um tipo espec√≠fico de molde: um modelo Sequencial.\n",
        "-- model = : Estamos guardando este molde vazio em uma vari√°vel chamada model.\n",
        "\n",
        "---\n",
        "\n",
        "**O que significa um modelo \"Sequencial\"?**\n",
        "\n",
        "Pense em montar um Lego. Um modelo Sequencial significa que vamos construir nosso c√©rebro em uma sequ√™ncia l√≥gica, uma camada de \"tijolos\" de Lego em cima da outra, em uma pilha reta e organizada. √â a forma mais simples, comum e direta de se construir uma rede neural.\n",
        "\n",
        " Analogia: A linha* model = tf.keras.models.Sequential()* √© como pegar aquela placa de Lego verde, plana e vazia. Ela ainda n√£o tem nenhuma pe√ßa, mas √© a base sobre a qual vamos come√ßar a empilhar nossos \"tijolos\" (as camadas de neur√¥nios)\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "**Agora, vamos adicionar as camadas de dados da nossa IA (layers)**"
      ],
      "metadata": {
        "id": "KtOQwsXwrEv8"
      },
      "id": "KtOQwsXwrEv8"
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(256, input_shape=x_train.shape, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(256, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "12WLwCemx9pF",
        "outputId": "44348733-ce3d-4683-9f2f-b3fb66db6201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "12WLwCemx9pF",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos analisar linha por linha, pois cada uma representa uma camada do nosso c√©rebro artificial.\n",
        "\n",
        "O Conceito-Chave: *model.add(tf.keras.layers.Dense(...))*\n",
        "\n",
        "- model.add(...): Este √© o comando para \"adicionar\" uma nova camada ao nosso esqueleto (model). Como nosso modelo √© Sequencial, cada add coloca uma nova camada em cima da anterior.\n",
        "- tf.keras.layers.Dense(...): Este √© o tipo de camada que estamos adicionando. Uma camada Dense (ou \"densa\") √© o tipo mais comum e fundamental. Ela significa que cada neur√¥nio nesta camada est√° conectado a todos os neur√¥nios da camada anterior. √â uma camada \"totalmente conectada\", o que permite que as informa√ß√µes se cruzem e se combinem de forma complexa.\n",
        "\n",
        "---\n",
        "\n",
        "*model.add(tf.keras.layers.Dense(256, input_shape=x_train.shape, activation='sigmoid'))*\n",
        "\n",
        "Esta √© a primeira camada que recebe os dados.\n",
        "\n",
        "- Dense(256, ...): O primeiro n√∫mero, 256, √© a quantidade de neur√¥nios (ou n√≥s) que esta camada ter√°. Pense neles como 256 pequenos \"calculadores\" que trabalhar√£o em paralelo para encontrar padr√µes. A escolha desse n√∫mero √© uma decis√£o de design; mais neur√¥nios podem aprender padr√µes mais complexos, mas tamb√©m tornam o modelo mais pesado.\n",
        "- input_shape=x_train.shape: Este par√¢metro √© especial e** usado apenas na primeira camada**. Ele diz ao modelo qual ser√° o formato dos dados de entrada. x_train.shape informa automaticamente o n√∫mero de colunas (features) que temos, para que o modelo crie as conex√µes de entrada corretamente.\n",
        "- activation='sigmoid': A fun√ß√£o de ativa√ß√£o √© como o \"interruptor de intensidade\" de um neur√¥nio. Depois que o neur√¥nio soma todos os sinais que recebe, a fun√ß√£o de ativa√ß√£o decide qual ser√° a for√ßa do sinal que ele passar√° para a pr√≥xima camada. A sigmoid espreme o resultado em um valor entre 0 e 1.\n",
        "\n",
        "---\n",
        "\n",
        "# Mas por que usamos essa fun√ß√£o?\n",
        "\n",
        "**Neur√¥nios recebem sinais de for√ßa de outros neur√¥nios anteriores, para basearem suas decis√µes**\n",
        "\n",
        "Imagine que um neur√¥nio √© um seguran√ßa na porta de uma balada muito exclusiva.\n",
        "\n",
        "1. Os Sinais que o Neur√¥nio Recebe\n",
        "Antes de voc√™, o seguran√ßa, tomar sua decis√£o, voc√™ observa v√°rias coisas sobre o grupo de pessoas que quer entrar. Cada uma dessas \"observa√ß√µes\" √© um sinal vindo da camada anterior de neur√¥nios.\n",
        "\n",
        "Sinal 1: A roupa da pessoa (vindo do neur√¥nio_roupa)\n",
        "Sinal 2: A educa√ß√£o da pessoa (vindo do neur√¥nio_educa√ß√£o)\n",
        "Sinal 3: O tom de voz da pessoa (vindo do neur√¥nio_tom_de_voz)\n",
        "S√≥ que para voc√™, o seguran√ßa, algumas coisas s√£o mais importantes que outras. A import√¢ncia que voc√™ d√° a cada sinal √© o \"peso\" daquela conex√£o.\n",
        "\n",
        "Roupa elegante: Peso +2.0 (muito importante, fator positivo)\n",
        "Educa√ß√£o: Peso +1.5 (importante, fator positivo)\n",
        "Tom de voz alto/agressivo: Peso -3.0 (muito importante, fator negativo)\n",
        "\n",
        "2. O Neur√¥nio Soma Todos os Sinais (A \"Primeira Impress√£o\")\n",
        "A primeira coisa que o neur√¥nio/seguran√ßa faz √© juntar todas essas informa√ß√µes para formar uma \"impress√£o bruta\". Ele multiplica a for√ßa de cada sinal pelo seu peso e soma tudo.\n",
        "\n",
        "Digamos que hoje ele recebeu os seguintes sinais:\n",
        "\n",
        "Roupa: 1 (boa) -> 1 * 2.0 = +2.0\n",
        "Educa√ß√£o: 0.8 (ok) -> 0.8 * 1.5 = +1.2\n",
        "Tom de voz: -1.5 (ruim) -> -1.5 * -3.0 = +4.5 (Opa, o tom de voz era ruim, mas como o peso era negativo, um sinal ruim x um peso negativo vira algo positivo na conta final - isso √© parte da m√°gica do aprendizado! Mas vamos simplificar).\n",
        "Vamos imaginar uma soma mais simples:\n",
        "\n",
        "Sinal da roupa (+5)\n",
        "Sinal da educa√ß√£o (+3)\n",
        "Sinal do tom de voz (-10)\n",
        "Soma Bruta Total: 5 + 3 - 10 = -2.\n",
        "\n",
        "Este valor, -2, √© o \"placar bruto\" ou a \"soma ponderada\". √â a primeira impress√£o do seguran√ßa. Pode ser qualquer n√∫mero, positivo ou negativo.\n",
        "\n",
        "3. A Fun√ß√£o de Ativa√ß√£o (A Decis√£o Final do Seguran√ßa)\n",
        "Agora vem a sua frase: \"a fun√ß√£o de ativa√ß√£o decide qual ser√° a for√ßa do sinal que ele passar√° para a pr√≥xima camada\".\n",
        "\n",
        "O seguran√ßa olhou para o placar bruto de -2. Ele n√£o pode simplesmente gritar \"-2!\" para o seguran√ßa da pr√≥xima √°rea (a √°rea VIP). Ele precisa traduzir essa impress√£o em uma decis√£o clara e padronizada.\n",
        "\n",
        "√â aqui que entra a Fun√ß√£o de Ativa√ß√£o (o nosso sigmoid). Ela √© o livro de regras do seguran√ßa.\n",
        "\n",
        "O livro de regras sigmoid diz:\n",
        "\n",
        "\"Qualquer que seja o seu placar bruto, voc√™ deve traduzi-lo em um 'n√≠vel de permiss√£o' entre 0% e 100% (ou 0 e 1).\"\n",
        "\"Se o placar for muito alto (ex: +50), seu n√≠vel de permiss√£o √© 100% (valor 1.0).\"\n",
        "\"Se o placar for muito baixo (ex: -40), seu n√≠vel de permiss√£o √© 0% (valor 0.0).\"\n",
        "\"Se o placar for exatamente 0, seu n√≠vel de permiss√£o √© 50% (valor 0.5).\"\n",
        "Ent√£o, o seguran√ßa pega o placar bruto -2 e consulta o livro de regras da Sigmoid. O resultado de sigmoid(-2) √© aproximadamente 0,12.\n",
        "\n",
        "Conclus√£o: O Sinal que Ele Passa Adiante\n",
        "A \"for√ßa do sinal\" que este neur√¥nio/seguran√ßa passa para a pr√≥xima camada √© 0,12.\n",
        "\n",
        "Ele n√£o passou o placar bruto de -2.\n",
        "Ele passou uma decis√£o normalizada e padronizada: \"Meu n√≠vel de entusiasmo/permiss√£o para este grupo √© de 12%\".\n",
        "Os neur√¥nios da pr√≥xima camada receber√£o este sinal de \"12% de for√ßa\" e o usar√£o em seus pr√≥prios c√°lculos para tomar suas pr√≥prias decis√µes.\n",
        "\n",
        "√â assim que a informa√ß√£o flui e √© transformada atrav√©s da rede: cada neur√¥nio recebe m√∫ltiplos sinais, faz uma soma ponderada para ter uma \"impress√£o bruta\" e, em seguida, usa sua fun√ß√£o de ativa√ß√£o para decidir com que \"intensidade\" (um valor entre 0 e 1, no caso da Sigmoid) ele vai passar essa informa√ß√£o adiante.\n",
        "\n",
        "---\n",
        "\n",
        "*model.add(tf.keras.layers.Dense(256, activation='sigmoid'))*\n",
        "\n",
        "Esta √© a nossa segunda camada, que recebe os sinais da primeira.\n",
        "\n",
        "Dense(256, ...): Novamente, estamos usando 256 neur√¥nios para continuar processando a informa√ß√£o.\n",
        "Sem input_shape: Note que n√£o precisamos mais dizer o formato da entrada. O Keras √© inteligente e j√° sabe que esta camada receber√° os 256 sinais da camada anterior.\n",
        "activation='sigmoid': Continuamos usando a mesma fun√ß√£o de ativa√ß√£o.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*model.add(tf.keras.layers.Dense(1, activation='sigmoid'))*\n",
        "\n",
        "Esta √© a camada final e mais importante para a nossa resposta. Diferente das outras camadas, ela n√£o √© oculta, √© ela que chamamos de resposta, e precisamos ver a resposta n√£o √©?\n",
        "\n",
        "- Dense(1, ...): Note que aqui temos apenas 1 neur√¥nio. Por qu√™? Porque nosso problema √© de classifica√ß√£o bin√°ria. Queremos uma √∫nica resposta: a probabilidade do tumor ser maligno (1) ou benigno (0). Um √∫nico neur√¥nio √© suficiente para nos dar essa √∫nica sa√≠da.\n",
        "- activation='sigmoid': Aqui, a fun√ß√£o sigmoid √© a escolha perfeita para a camada de sa√≠da. Como ela sempre resulta em um valor entre 0 e 1, podemos interpretar diretamente a sa√≠da do nosso modelo como uma probabilidade.\n",
        "Se o modelo cuspir 0.95, ele est√° 95% confiante de que o diagn√≥stico √© '1' (maligno).\n",
        "Se ele cuspir 0.02, ele est√° 2% confiante de que √© '1' (ou seja, 98% confiante de que √© '0', benigno).\n",
        "\n",
        "---\n",
        "\n",
        "# Mas como saber quantos neur√¥nios vamos usar no c√≥digo?\n",
        "\n",
        "Essa √© uma pergunta de milh√µes nos c√≥digos de IA! A resposta √© depende. Depende do problema que voc√™ quer resolver.\n",
        "\n",
        "Vamos analisar isso ao longo das aulas\n",
        "\n",
        "---\n",
        "\n",
        "**Temos a arquitetura montada, mas como ela vai aprender?**"
      ],
      "metadata": {
        "id": "DZ-ceZ5m0ltK"
      },
      "id": "DZ-ceZ5m0ltK"
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lEcwBVF_Coos"
      },
      "id": "lEcwBVF_Coos",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])*\n",
        "\n",
        "Vamos quebrar cada um desses tr√™s \"par√¢metros\":\n",
        "\n",
        "1. *optimizer='adam':* **O GPS para Encontrar a Melhor Resposta**\n",
        "- O que √© um optimizer (otimizador)? √â o m√©todo que o modelo usar√° para ajustar seus \"pesos\" internos e melhorar suas previs√µes. A cada resposta errada, o otimizador calcula em qual dire√ß√£o e com que intensidade ele deve ajustar seus neur√¥nios para errar menos na pr√≥xima vez.\n",
        "- Analogia: Imagine que o seu modelo est√° no topo de uma montanha nebulosa e o objetivo √© chegar ao ponto mais baixo do vale (o ponto de menor erro). O otimizador √© o seu GPS ou Waze. Ele te diz \"d√™ um passo para a esquerda... agora um passo um pouco maior para frente...\" para te guiar at√© o fundo do vale da forma mais eficiente poss√≠vel.\n",
        "- Por que 'adam'? Adam √© um  dos otimizadores mais populares e eficientes que existem. Ele √© adaptativo, o que significa que ele ajusta a \"velocidade\" do aprendizado conforme avan√ßa. √â uma escolha padr√£o excelente, como usar o Waze em vez de um mapa de papel.\n",
        "---\n",
        "2. *loss='binary_crossentropy':* **A \"Nota\" do Erro do Modelo**\n",
        "- O que √© a loss (fun√ß√£o de perda)? √â a f√≥rmula matem√°tica que calcula o qu√£o \"errado\" o modelo est√°. Ela compara a previs√£o do modelo com a resposta correta e gera um n√∫mero. Quanto maior o n√∫mero, maior o erro.\n",
        "O √∫nico objetivo do modelo durante o treinamento √© fazer com que o valor da loss seja o menor poss√≠vel.\n",
        "- Analogia: Se o otimizador √© o GPS, a fun√ß√£o de perda √© a altitude. O GPS usa a altitude para saber se est√° subindo ou descendo. O modelo usa a loss para saber se suas previs√µes est√£o melhorando ou piorando.\n",
        "Por que 'binary_crossentropy'? O nome parece complicado, mas a ideia √© simples. Esta √© a fun√ß√£o de perda perfeita para classifica√ß√£o bin√°ria (0 ou 1), especialmente quando a sa√≠da do seu modelo √© uma probabilidade (gra√ßas √† nossa camada final com sigmoid). Ela penaliza severamente o modelo quando ele est√° muito confiante, mas errado (ex: prever 99% de chance de ser maligno quando na verdade era benigno).\n",
        "---\n",
        "3. *metrics=['accuracy']:* **O Boletim para N√≥s, Humanos**\n",
        "- O que s√£o metrics (m√©tricas)? S√£o as medidas que n√≥s, os humanos, queremos ver para avaliar o desempenho do modelo. Elas n√£o s√£o usadas pelo modelo para aprender (ele s√≥ se importa com a loss), mas s√£o impressas na tela para nos informar sobre o progresso.\n",
        "- Analogia: A loss √© a \"dificuldade\" que o aluno sente ao estudar, e ele tenta minimizar essa dificuldade. A accuracy √© a nota no boletim que o professor mostra aos pais.\n",
        "- Por que ['accuracy']? Estamos pedindo: \"Al√©m de tentar minimizar a loss, por favor, me mostre tamb√©m a acur√°cia (a porcentagem de acertos) a cada etapa do treino\". √â a m√©trica mais intuitiva para entendermos rapidamente se nosso modelo est√° indo bem.\n",
        "\n",
        "---\n",
        "\n",
        "Mas poxa vida, s√≥ escrevemos c√≥digo e nada acontece...\n",
        "\n",
        "**Passo 6: Finalmente colocamos a IA em a√ß√£o**\n"
      ],
      "metadata": {
        "id": "4kMmNo9qDENs"
      },
      "id": "4kMmNo9qDENs"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=1000)"
      ],
      "metadata": {
        "id": "iCHxSSi9J3AW",
        "outputId": "bc6e8cbf-05a1-4db1-ca23-0fd38f8c98f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "id": "iCHxSSi9J3AW",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 30), dtype=float32). Expected shape (None, 455, 30), but input has incompatible shape (None, 30)\u001b[0m\n\nArguments received by Sequential.call():\n  ‚Ä¢ inputs=tf.Tensor(shape=(None, 30), dtype=float32)\n  ‚Ä¢ training=True\n  ‚Ä¢ mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-3605916656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 30), dtype=float32). Expected shape (None, 455, 30), but input has incompatible shape (None, 30)\u001b[0m\n\nArguments received by Sequential.call():\n  ‚Ä¢ inputs=tf.Tensor(shape=(None, 30), dtype=float32)\n  ‚Ä¢ training=True\n  ‚Ä¢ mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*model.fit(x_train, y_train, epochs=1000)*\n",
        "\n",
        "Esta linha de c√≥digo diz ao nosso modelo: \"Agora, comece a treinar!\". √â o apito inicial, o come√ßo do \"training montage\" do filme.\n",
        "\n",
        "- *model.fit(...):* O nome da fun√ß√£o, .fit(), vem da ideia de \"ajustar\" (to fit) os par√¢metros internos do modelo aos dados. √â o comando que inicia o ciclo de treinamento.\n",
        "Vamos analisar os \"ingredientes\" que damos para este treino:\n",
        "\n",
        "- 1. x_train: O Material de Estudo (As Perguntas)\n",
        "Este √© o primeiro argumento que passamos. √â o nosso conjunto de treino com todas as evid√™ncias (as caracter√≠sticas dos tumores).\n",
        "Analogia: Entregamos ao nosso \"aluno-rob√¥\" o livro com todos os exerc√≠cios e exemplos que ele precisa estudar.\n",
        "- 2. y_train: O Gabarito (As Respostas)\n",
        "Este √© o segundo argumento. √â o conjunto com os diagn√≥sticos corretos que correspondem a cada exemplo em x_train.\n",
        "Analogia: Junto com o livro de exerc√≠cios (x_train), entregamos o gabarito com as respostas corretas (y_train). O aluno usa o gabarito para verificar se est√° acertando e para corrigir seus erros.\n",
        "- 3. epochs=1000: A Dura√ß√£o do Treino (Repeti√ß√£o)\n",
        "Este √© um dos par√¢metros mais importantes do treinamento.\n",
        "- O que √© uma \"√âpoca\" (Epoch)? Uma √©poca significa uma passada completa por todo o material de estudo. Se o nosso x_train tem 455 amostras, uma √©poca termina quando o modelo viu todas as 455 amostras uma vez.\n",
        "- Por que 1000? Estamos dizendo ao nosso modelo para estudar o material de treino completo 1000 vezes. A cada vez, ele tenta refinar um pouco mais seu conhecimento. O aprendizado de uma rede neural √© um processo gradual e repetitivo. Ela n√£o aprende tudo de uma vez. A cada √©poca, ela ajusta seus pesos para tentar diminuir a loss (o erro) e aumentar a accuracy (a acur√°cia).\n",
        "- Analogia: epochs=1000 √© como dizer ao atleta para fazer sua rotina de treino completa (correr, pular, levantar pesos) 1000 vezes at√© a competi√ß√£o. A cada repeti√ß√£o, ele fica um pouco mais forte, mais r√°pido e mais preciso.\n",
        "\n",
        "---\n",
        "\n",
        "# Mas por que 1000 epochs?\n",
        "- A resposta curta √©: Voc√™ treina o suficiente para o modelo aprender os padr√µes, mas para ANTES que ele comece a decorar o material de estudo. Iremos falar sobre isso no final desse c√≥digo!\n",
        "\n",
        "---\n",
        "E agora?\n",
        "\n",
        "-\n",
        "Quando voc√™ executar esta linha, ver√° o treinamento acontecendo em tempo real. O Colab ir√° mostrar uma barra de progresso para cada uma das 1000 √©pocas e, ao final de cada uma, exibir√° os valores da loss e da accuracy.\n",
        "\n",
        "Idealmente, voc√™ ver√° o valor da loss diminuir e o da accuracy aumentar a cada √©poca, mostrando que seu modelo est√°, de fato, aprendendo!"
      ],
      "metadata": {
        "id": "srcMp6Z7KkB3"
      },
      "id": "srcMp6Z7KkB3"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}